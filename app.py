# -*- coding: utf-8 -*-
"""Supply Chain.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1o4-AVMFNtsgwVsjeTBLFyx98T6_7wsJ-

# 1. EXTRACT, TRANSFORM, LOAD (ETL)

## a. Extracting data from sources
"""

import pandas as pd
df = pd.read_csv('DataCoSupplyChainDataset.csv',encoding='latin1')

"""## b. Transforming data to fit analytic needs"""

# Rename kolom agar rapi
df.columns = df.columns.str.lower().str.replace(" ", "_")

# Parsing tanggal
df['order_date_(dateorders)'] = pd.to_datetime(df['order_date_(dateorders)'])
df['shipping_date_(dateorders)'] = pd.to_datetime(df['shipping_date_(dateorders)'])

# Feature engineering
df['shipping_delay'] = (
    df['shipping_date_(dateorders)'] - df['order_date_(dateorders)']
).dt.days

df['order_month'] = df['order_date_(dateorders)'].dt.to_period('M').astype(str)

"""## c. Loading data into business systems"""

df_etl = df

"""# 2. DATA CLEANING

## a. Summarizing data
"""

df_etl.info()

df_etl.describe()

df_etl.isna().sum()

"""## b. Finding & fixing flawed data"""

# Missing value handling
df_etl['customer_lname'].fillna("Unknown", inplace=True)
df_etl['customer_zipcode'].fillna(df_etl['customer_zipcode'].mode()[0], inplace=True)

# Kolom dengan missing sangat besar â†’ drop
df_etl.drop(columns=['product_description'], inplace=True)

"""## c. Converting data types"""

df_etl['late_delivery_risk'] = df_etl['late_delivery_risk'].astype('category')
df_etl['order_status'] = df_etl['order_status'].astype('category')

"""## d. Adapting string variables"""

df_etl['customer_city'] = df_etl['customer_city'].str.title()
df_etl['market'] = df_etl['market'].str.upper()

"""# 3. EXPLORATORY DATA ANALYSIS (EDA)

## a. Implementing EDA
"""

import seaborn as sns
import matplotlib.pyplot as plt
sns.set(style="whitegrid")

"""## b. Single variable analysis (Histogram)"""

sns.histplot(df_etl['sales'], bins=30, kde=True)
plt.title("Distribution of Sales")
plt.show()

"""# c. Two variables analysis (Boxplot)"""

sns.boxplot(x='order_status', y='sales', data=df_etl)
plt.title("Sales by Order Status")
plt.show()

sns.violinplot(x='order_status', y='sales', data=df_etl)
plt.title("Sales Distribution by Order Status")
plt.show()

"""## d. Multiple variables analysis (Bar)"""

pivot = df_etl.pivot_table(
    values='sales',
    index='order_month',
    columns='market',
    aggfunc='sum'
)

pivot.plot(figsize=(10,5))
plt.title("Monthly Sales by Market")
plt.show()

"""# 4. LINEAR REGRESSION FOR BUSINESS

## a. Implementing linear regression
"""

import statsmodels.api as sm

X = df_etl[['order_item_quantity', 'shipping_delay']]
y = df_etl['sales']

X = sm.add_constant(X)
model = sm.OLS(y, X).fit()
print(model.summary())

"""## b. Checking assumptions"""

# Normalitas (Residual)
sns.histplot(model.resid, kde=True)
plt.title("Residual Distribution")
plt.show()

# Homoskedastisitas
sns.scatterplot(x=model.fittedvalues, y=model.resid)
plt.axhline(0, color='red')
plt.title("Homoskedasticity Check")
plt.show()

# Autokorelasi (Durbin-Watson)
from statsmodels.stats.stattools import durbin_watson
durbin_watson(model.resid)

# Multikolinearitas (VIF)
from statsmodels.stats.outliers_influence import variance_inflation_factor

vif = pd.DataFrame()
vif["VIF"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]
vif["variable"] = X.columns
vif

"""## c. Interpreting model

Koefisien (+) = menaikkan sales, p-value < 0.05 = signifikan

## d. Refining data
"""

X_simple = sm.add_constant(df_etl[['order_item_quantity']])
model_simple = sm.OLS(y, X_simple).fit()
print(model_simple.summary())

"""# 5. CLUSTER ANALYSIS

## a. Explaining clustering

Clustering adalah metode unsupervised learning untuk mengelompokkan data berdasarkan kemiripan karakteristik tanpa label awal. Dalam konteks supply chain, clustering digunakan untuk mengelompokkan pesanan berdasarkan pola penjualan dan kuantitas guna mendukung pengambilan keputusan logistik dan inventori.

## b. K-Means
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler


# pilih variabel
cluster_data = df_etl[['sales', 'order_item_quantity']]

# scaling
scaler = StandardScaler()
scaled = scaler.fit_transform(cluster_data)

# KMeans
kmeans = KMeans(n_clusters=3, random_state=42)
df_etl['cluster_kmeans'] = kmeans.fit_predict(scaled)

# distribusi cluster
print(df_etl['cluster_kmeans'].value_counts())

cluster_summary = (
    df_etl
    .groupby('cluster_kmeans')[['sales', 'order_item_quantity']]
    .mean()
    .round(2)
)

cluster_summary

cluster_labels = {
    0: 'Small Orders',
    1: 'Medium Orders',
    2: 'Large / Bulk Orders'
}

df_etl['cluster_label'] = df_etl['cluster_kmeans'].map(cluster_labels)
df_etl['cluster_label'].value_counts()

plt.figure(figsize=(8,6))
sns.scatterplot(
    data=df_etl,
    x='sales',
    y='order_item_quantity',
    hue='cluster_label',
    palette='Set2',
    alpha=0.6
)
plt.title('K-Means Clustering of Orders')
plt.xlabel('Sales')
plt.ylabel('Order Quantity')
plt.legend(title='Order Segment')
plt.show()

"""## c. Hierarchical clustering"""

# ambil sampel kecil
df_hier = df[['sales', 'order_item_quantity']].sample(
    n=500, random_state=42
)

scaled_hier = scaler.fit_transform(df_hier)

from scipy.cluster.hierarchy import linkage, dendrogram
import matplotlib.pyplot as plt

linked = linkage(scaled_hier, method='ward')

plt.figure(figsize=(10,4))
dendrogram(linked, truncate_mode='lastp', p=10)
plt.show()

df.groupby('cluster_kmeans')[['sales','order_item_quantity']].mean()

"""# 6. TIME SERIES ANALYSIS

## a. Linear regression time series
"""

import statsmodels.api as sm
ts = df_etl.groupby('order_month')['sales'].sum().reset_index()
ts['t'] = range(len(ts))

X_ts = sm.add_constant(ts['t'])
model_ts = sm.OLS(ts['sales'], X_ts).fit()
print(model_ts.summary())

"""## b. Key elements

Trend

Seasonality

Noise

## c. ARIMA
"""

from statsmodels.tsa.arima.model import ARIMA

arima = ARIMA(ts['sales'], order=(1,1,1))
arima_model = arima.fit()
arima_model.summary()

"""# 7. VISUALIZING DATA STORY

## a & b. Plotly interactive
"""

import plotly.express as px

fig = px.pie(df_etl, names='order_status', title='Order Status Composition')
fig.show()

"""## c. Geo-mapping (Folium)"""

import folium

m = folium.Map(location=[0,0], zoom_start=2)

for _, row in df_etl.sample(100).iterrows():
    folium.CircleMarker(
        location=[row['latitude'], row['longitude']],
        radius=3
    ).add_to(m)

m

"""## d. Interactive graphics (Plotly)"""

px.scatter(
    df_etl,
    x='sales',
    y='order_item_quantity',
    color='cluster_kmeans',
    title="Customer Segmentation (K-Means)"
)

"""# 8. WEB DASHBOARD (DASH)"""

from dash import Dash, html, dcc
import plotly.express as px

# time series
ts = df_etl.groupby('order_month', as_index=False)['sales'].sum()

# market aggregation
market_sales = df_etl.groupby('market', as_index=False)['sales'].sum()

app = Dash(__name__)

app.layout = html.Div([

    html.H1(
        "Supply Chain Dashboard",
        style={'textAlign': 'center'}
    ),

    # Pie Chart
    dcc.Graph(
        figure=px.pie(
            df_etl,
            names='order_status',
            title='Order Status Distribution'
        )
    ),

    # Line Chart
    dcc.Graph(
        figure=px.line(
            ts,
            x='order_month',
            y='sales',
            title='Monthly Sales Trend'
        )
    ),

    # Bar Chart
    dcc.Graph(
        figure=px.bar(
            market_sales,
            x='market',
            y='sales',
            title='Total Sales by Market'
        )
    ),

    # Scatter Cluster
    dcc.Graph(
        figure=px.scatter(
            df_etl,
            x='sales',
            y='order_item_quantity',
            color='cluster_label',
            title='Customer Segmentation'
        )
    )
])

if __name__ == "__main__":
    app.run_server(host="0.0.0.0", port=8050)